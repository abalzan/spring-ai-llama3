
### How to run the Ollama Chatbot locally:
https://github.com/ollama/ollama

### Test id llama is running locally:
curl -X POST http://localhost:11434/api/generate -d '{"model":"llama3", "prompt": "who is the current president of republic of Ireland"}'

### Spring Ai Documentation reference:
https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html

### sample call using your browser:
[http://localhost:8080/api/v1/generate?promptMessage=who is the current president of republic of ireland](localhost:8080/api/v1/generate?promptMessage=who is the current president of republic of ireland)